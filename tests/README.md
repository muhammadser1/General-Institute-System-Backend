# Test Suite Documentation

## ðŸ“ Structure

```
tests/
â”œâ”€â”€ conftest.py              # Shared fixtures and configuration
â”œâ”€â”€ requirements-test.txt    # Testing dependencies
â”œâ”€â”€ user/                    # User module tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_user_model.py   # User model unit tests (70+ tests)
â”‚   â”œâ”€â”€ test_deps.py         # Authentication & authorization tests (20+ tests)
â”‚   â””â”€â”€ test_user_routes.py  # User endpoint integration tests (30+ tests)
â””â”€â”€ README.md               # This file
```

## ðŸš€ Setup

### Install All Dependencies (including tests)

```bash
pip install -r requirements.txt
```

All dependencies (production + testing) are now in one file!

## â–¶ï¸ Running Tests

### Run All Tests
```bash
pytest
```

### Run Specific Test File
```bash
pytest tests/user/test_user_model.py
pytest tests/user/test_deps.py
pytest tests/user/test_user_routes.py
```

### Run Specific Test Class
```bash
pytest tests/user/test_user_model.py::TestUserBusinessLogic
```

### Run Specific Test Function
```bash
pytest tests/user/test_user_model.py::TestUserBusinessLogic::test_is_active_returns_true_for_active_user
```

### Run with Markers
```bash
# Run only unit tests
pytest -m unit

# Run only integration tests
pytest -m integration

# Run only user tests
pytest -m user
```

### Run with Coverage Report
```bash
pytest --cov=app --cov-report=html
```

Then open `htmlcov/index.html` in your browser to see detailed coverage.

### Run with Verbose Output
```bash
pytest -v
```

### Run and Stop on First Failure
```bash
pytest -x
```

### Run Last Failed Tests Only
```bash
pytest --lf
```

## ðŸ“Š Test Coverage

### User Module Test Coverage

#### **test_user_model.py** - 70+ Unit Tests
- âœ… User creation with required/optional fields
- âœ… User ID auto-generation
- âœ… Business logic methods (is_active, is_admin, is_teacher, get_full_name)
- âœ… Data conversion (to_dict, from_dict)
- âœ… Database operations (find, save, update, exists checks)
- âœ… Roundtrip conversions
- âœ… String representation

#### **test_deps.py** - 20+ Integration Tests
- âœ… Token validation
- âœ… User authentication
- âœ… User authorization (admin/teacher)
- âœ… Invalid token handling
- âœ… Expired token handling
- âœ… Inactive/suspended user handling
- âœ… Dependency chaining
- âœ… Security headers

#### **test_user_routes.py** - 30+ Integration Tests
- âœ… Login endpoint (success, failures, validation)
- âœ… Logout endpoint (authenticated, unauthenticated)
- âœ… Get profile endpoint (/me)
- âœ… Teacher signup endpoint (success, duplicates, validation)
- âœ… Full user flow integration (signup â†’ login â†’ profile)
- âœ… Password hashing
- âœ… Role enforcement

## ðŸŽ¯ Test Categories

### Unit Tests (Fast)
- Test individual functions/methods in isolation
- No database or network calls
- Mock all dependencies
- **Location**: `test_user_model.py`

### Integration Tests (Medium)
- Test multiple components together
- Use mock database (mongomock)
- Test API endpoints
- **Location**: `test_deps.py`, `test_user_routes.py`

### E2E Tests (Slow)
- Test complete user flows
- Use real-like environment
- **Location**: Integration test classes with `TestEndpointIntegration`

## ðŸ”§ Writing New Tests

### 1. Model Tests Example
```python
def test_my_new_feature():
    """Test description"""
    user = User(username="test", hashed_password="hash")
    
    result = user.my_new_method()
    
    assert result == expected_value
```

### 2. Endpoint Tests Example
```python
def test_my_endpoint(client, mock_db):
    """Test description"""
    # Setup
    with patch('app.api.v1.endpoints.user.mongo_db') as mock_mongo:
        mock_mongo.users_collection = mock_db["users"]
        
        # Execute
        response = client.post("/api/v1/user/endpoint", json={...})
        
        # Assert
        assert response.status_code == 200
        assert response.json()["key"] == "value"
```

## ðŸ† Best Practices

1. âœ… **One assertion per test** (when possible)
2. âœ… **Descriptive test names** (`test_what_when_expected`)
3. âœ… **AAA Pattern**: Arrange, Act, Assert
4. âœ… **Use fixtures** for common setup
5. âœ… **Mock external dependencies**
6. âœ… **Test edge cases** and error conditions
7. âœ… **Keep tests independent**
8. âœ… **Clean up after tests**

## ðŸ“ˆ Continuous Integration

### GitHub Actions Example
```yaml
- name: Run tests
  run: |
    pip install -r tests/requirements-test.txt
    pytest --cov=app --cov-report=xml
```

## ðŸ› Debugging Tests

### Run with Print Statements
```bash
pytest -s
```

### Run with Debugger
```bash
pytest --pdb
```

### See Full Error Traceback
```bash
pytest --tb=long
```

## ðŸ“ Current Test Statistics

- **Total Tests**: 120+
- **User Model Tests**: 70+
- **Dependencies Tests**: 20+
- **Routes Tests**: 30+
- **Coverage Target**: >90%

## ðŸŽ¨ Test Report

After running tests with coverage:
```bash
pytest --cov=app --cov-report=term-missing
```

You'll see:
- Lines covered/missed
- Percentage coverage per file
- Missing line numbers

## âš¡ Performance

- **Unit tests**: ~0.001s each
- **Integration tests**: ~0.1-0.5s each
- **Full suite**: ~5-10s

## ðŸ”’ Security Testing

Tests include:
- âœ… Password hashing verification
- âœ… Token validation
- âœ… Authorization checks
- âœ… Input validation
- âœ… SQL injection prevention (via MongoDB)
- âœ… XSS prevention (via Pydantic)

